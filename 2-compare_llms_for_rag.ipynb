{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/PV/envs/llm_work_space/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "\n",
    "#from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoConfig\n",
    "#from Chatting_with_docs_via_LLMs.utils import *\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import transformers\n",
    "import PyPDF2\n",
    "import pandas as pd \n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading a PDF: It defines a function read_pdf_with_pypdf2 that opens a PDF file and extracts its text using PyPDF2. This text is concatenated into a single string, returned at the end of the function.\n",
    "\n",
    "#Processing the text: After reading the PDF (\"The-Field-Guide-to-Data-Science.pdf\"), it splits the extracted text into smaller chunks using RecursiveCharacterTextSplitter, which breaks the text based on a specified chunk size and overlap.\n",
    "\n",
    "#Document wrapping: Each chunk is then converted into a Document object, preparing it for further processing.\n",
    "\n",
    "#Embedding generation: Using the HuggingFace's transformers, it loads a pre-trained model (sentence-transformers/all-MiniLM-L6-v2) to generate normalized embeddings for the chunks of text.\n",
    "\n",
    "#Database creation: Constructs a Chroma database from the documents with their embeddings. This database is used to store and manage the text data in a structured format.\n",
    "\n",
    "#Retriever initialization: Initializes a retriever on the created database to facilitate similarity search, allowing the retrieval of the top k (5) most similar documents based on the embeddings.\n",
    "\n",
    "\n",
    "def read_pdf_with_pypdf2(file_path):\n",
    "    text = ''\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text() + '\\n'  \n",
    "    \n",
    "    return text\n",
    "\n",
    "pdf_path = \"The-Field-Guide-to-Data-Science.pdf\"\n",
    "text = read_pdf_with_pypdf2(pdf_path)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=64,\n",
    "    length_function=len)\n",
    "\n",
    "chunks = text_splitter.split_text(text=text)\n",
    "new_chunks = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents=new_chunks, \n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration loading: Loads the configuration for the specified model_name using AutoConfig.from_pretrained. This configuration adapts the model to the specific requirements and settings.\n",
    "\n",
    "# Tokenizer setup: Initializes the tokenizer with AutoTokenizer.from_pretrained, setting it to trust remote code. The pad token is then set to be the same as the end-of-sentence (EOS) token, ensuring consistent token padding during text generation.\n",
    "\n",
    "# Model instantiation: Loads a pre-trained causal language model (for generating text) using AutoModelForCausalLM.from_pretrained and moves it to the CUDA device for GPU-accelerated computation.\n",
    "\n",
    "# Pipeline creation: Establishes a text-generation pipeline with the loaded model and tokenizer, setting various parameters like temperature, repetition_penalty, and max_new_tokens to control the generation process. do_sample is set to True for probabilistic token sampling, and the device is set to -1 (typically meaning CPU).\n",
    "\n",
    "# Wrapper object creation: Wraps the configured pipeline into a HuggingFacePipeline object, which provides a convenient interface for interacting with the model.\n",
    "\n",
    "# Return the model wrapper: Returns the llm_model, which is the HuggingFacePipeline object ready for generating text based on the input model and configuration.\n",
    "\n",
    "def create_model(model_name,hf_token=None,token_size = 6144):\n",
    "    \n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    model = model.to('cuda') \n",
    "\n",
    "\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.1,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=True,\n",
    "        max_new_tokens=token_size,\n",
    "        do_sample=True,\n",
    "        device=-1  \n",
    "    )\n",
    "\n",
    "    llm_model = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "    \n",
    "    return llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template setup: Defines a template for the QA task instructing the assistant to use provided context to answer questions concisely within five sentences.\n",
    "\n",
    "# Prompt initialization: Creates a ChatPromptTemplate object from the defined template, which formats incoming questions and context into a consistent structure for processing.\n",
    "\n",
    "# Retrieval-augmented generation (RAG) chain: Sets up a processing chain starting with context retrieval (retriever), followed by question parsing (RunnablePassthrough()), text generation using the llm_model, and finally parsing the output into a structured format (StrOutputParser()).\n",
    "\n",
    "# Question definition: Lists specific questions related to Data Science concepts as outlined in a guide, which will be used to test the QA process.\n",
    "\n",
    "# Answer generation: Iterates through the defined questions, invoking the RAG chain for each question to generate answers, which are then stored in an answers list.\n",
    "\n",
    "# Response compilation: Creates a dictionary llm_response containing both the questions and their corresponding answers.\n",
    "\n",
    "# Return the result: Returns lll_response, which includes the questions posed and the answers generated by the language model, demonstrating the QA capability of the system.\n",
    "\n",
    "def chain_and_QA_process(llm_model):\n",
    "    \n",
    "    template = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use five sentences maximum and keep the answer concise.\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "        | prompt \n",
    "        | llm_model\n",
    "        | StrOutputParser() \n",
    "    )\n",
    "\n",
    "    query = [\"What are the fundamental differences between deductive and inductive reasoning in the context of Data Science, as outlined in the guide?\",\\\n",
    "             \"How does the guide describe the transformation of data into actionable insights through the creation of data products?\",\\\n",
    "             \"According to the guide, what role does the Data Lake play in the preparation and analysis of data for Data Science endeavors?\",\\\n",
    "             \"Can you explain the concept of 'Data Science Maturity' within an organization as presented in the guide, and how does it impact the organization's analytical capabilities?\",\\\n",
    "             \"The guide mentions a 'Data Science Venn Diagram' that includes domain expertise, computer science, and mathematics. How does this diagram illustrate the interdisciplinary nature of Data Science, and why are these areas critical?\"]\n",
    "\n",
    "    answers = []\n",
    "\n",
    "    for i in query:\n",
    "        answers.append(rag_chain.invoke(i))\n",
    "\n",
    "    llm_response = {\"Questions\":query,\\\n",
    "                   \"Answers\":answers}\n",
    "\n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are going to use 4 different model for RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## *Model Llama-2-13b-chat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /opt/app-root/src/PV/cache/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "huggingface_token = \"huggingface_token\"\n",
    "\n",
    "login(huggingface_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce68da8bb0474829a2f2ab56f02a4c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae95adf72f1145538a8fa80573baad7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='meta-llama/Llama-2-13b-chat-hf'\n",
    "\n",
    "llama_2_13b = create_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/PV/envs/llm_work_space/lib/python3.10/site-packages/transformers/generation/utils.py:2677: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /opt/app-root/src/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the fundamental differences between deductive and inductive reasoning in the context of Data Science, as outlined in the guide?\n",
      "Answer:  The fundamental differences between deductive and inductive reasoning in the context of Data Science are:\n",
      "     * Deductive reasoning involves reasoning from known premises to a certain conclusion, while inductive reasoning involves drawing uncertain inferences based on probabilistic reasoning.\n",
      "     * Data Science combines both deductive and inductive reasoning to create an environment where models of reality are constantly tested, updated, and improved until better models are found.\n",
      "     * Data Science emphasizes the use of inductive reasoning to discover new relationships and insights from the data, while deductive reasoning is used to formulate hypotheses and carry out experiments to test those hypotheses.\n",
      "\n",
      "Question: How does the guide describe the transformation of data into actionable insights through the creation of data products?\n",
      "Answer:  Based on the provided context, the guide describes the transformation of data into actionable insights through the creation of data products, which provide actionable information without exposing decision makers to the underlying data or analytics. The guide highlights the importance of extracting timely and actionable information from diverse data sources to drive data products, and emphasizes the shift from traditional analysis approaches to inductive and deductive reasoning. Additionally, the guide notes that organizations can directly connect business decision makers to the data, allowing them to value the data rather than managing it as something separate.\n",
      "\n",
      "Question: According to the guide, what role does the Data Lake play in the preparation and analysis of data for Data Science endeavors?\n",
      "Answer:  The Data Lake plays a crucial role in the preparation and analysis of data for Data Science endeavors by providing a centralized repository of all the organization's data, eliminating the need for ETL and enabling real-time analysis of all the data.\n",
      "\n",
      "Question: Can you explain the concept of 'Data Science Maturity' within an organization as presented in the guide, and how does it impact the organization's analytical capabilities?\n",
      "Answer:  The concept of \"Data Science Maturity\" refers to an organization's ability to utilize data to drive decision-making and improve its analytical capabilities. It is a model that assesses an organization's progress in developing its data science capabilities, from basic data collection and description to more advanced predictive and advisory activities. The model has five stages of maturity, ranging from collecting and describing data to predicting and advising. Organizations that reach the highest levels of maturity, known as the \"Advise\" stage, are able to use data to gain true insights and achieve real competitive advantage. To create a data science capability, organizations must build a robust team with a broad view of the organization, and leaders must foster trust and transparent communication across all levels.\n",
      "\n",
      "Question: The guide mentions a 'Data Science Venn Diagram' that includes domain expertise, computer science, and mathematics. How does this diagram illustrate the interdisciplinary nature of Data Science, and why are these areas critical?\n",
      "Answer:  The Data Science Venn Diagram illustrates the interdisciplinary nature of Data Science by showing the overlap between computer science, mathematics, and domain expertise. These areas are critical because they provide the foundation for creating data products, understanding the problem space, and examining data science problems theoretically. Building a successful Data Science capability requires a diverse set of skills, including computer science, mathematics, and domain expertise, to create a winning team that can achieve improved insights.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_response = chain_and_QA_process(llama_2_13b)\n",
    "\n",
    "for i,j in zip(llm_response[\"Questions\"],llm_response[\"Answers\"]):\n",
    "    print(f\"Question: {i}\\nAnswer: {j}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm-model</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>What are the fundamental differences between d...</td>\n",
       "      <td>The fundamental differences between deductive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>How does the guide describe the transformation...</td>\n",
       "      <td>Based on the provided context, the guide desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>According to the guide, what role does the Dat...</td>\n",
       "      <td>The Data Lake plays a crucial role in the pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>Can you explain the concept of 'Data Science M...</td>\n",
       "      <td>The concept of \"Data Science Maturity\" refers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>The guide mentions a 'Data Science Venn Diagra...</td>\n",
       "      <td>The Data Science Venn Diagram illustrates the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             llm-model                                          Questions  \\\n",
       "0  Llama-2-13b-chat-hf  What are the fundamental differences between d...   \n",
       "1  Llama-2-13b-chat-hf  How does the guide describe the transformation...   \n",
       "2  Llama-2-13b-chat-hf  According to the guide, what role does the Dat...   \n",
       "3  Llama-2-13b-chat-hf  Can you explain the concept of 'Data Science M...   \n",
       "4  Llama-2-13b-chat-hf  The guide mentions a 'Data Science Venn Diagra...   \n",
       "\n",
       "                                             Answers  \n",
       "0   The fundamental differences between deductive...  \n",
       "1   Based on the provided context, the guide desc...  \n",
       "2   The Data Lake plays a crucial role in the pre...  \n",
       "3   The concept of \"Data Science Maturity\" refers...  \n",
       "4   The Data Science Venn Diagram illustrates the...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(llm_response)\n",
    "df_results[\"llm-model\"] = \"Llama-2-13b-chat-hf\"\n",
    "df_results = df_results[[\"llm-model\",\"Questions\",\"Answers\"]]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model Mistral-7B-Instruct-v0.2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e5e73b96f54942994e1abc214a256c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207d140473084113bcb1de1884cc3e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c92f82aca642b2b7ea829ecfc44774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1bcc0f8ed44aa1a0bc5616040f28ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efba86789c14cce81b7bbea25885adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "mistral_llm = create_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/app-root/src/PV/envs/llm_work_space/lib/python3.10/site-packages/transformers/generation/utils.py:2677: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /opt/app-root/src/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the fundamental differences between deductive and inductive reasoning in the context of Data Science, as outlined in the guide?\n",
      "Answer: 1. Deductive reasoning is commonly associated with formal logic, involving reasoning from known premises to a certain conclusion, while inductive reasoning is commonly known as informal logic or everyday argument, involving drawing uncertain inferences based on probabilistic reasoning.\n",
      "    2. In Data Science, both deductive and inductive reasoning play important roles. Deductive reasoning is used to formulate hypotheses about relationships and underlying models, while inductive reasoning is used for exploratory data analysis to discover or refine hypotheses and discover new relationships, insights, and analytic paths from the data.\n",
      "    3. Data Science creates an environment where models of reality are constantly tested, updated, and improved until better models are found, unlike traditional analytic approaches where models are static and empirically based.\n",
      "    4. Data Science is focused on obtaining actionable information from data as opposed to reporting historical facts, making it a forward-looking capability compared to Business Intelligence, which is backward-looking.\n",
      "    5. Data Science offers a distinct perspective and adds value to Business Intelligence by working on discovering the question to ask as opposed to just asking it, providing the power of many through an entire team, and focusing on prospective analysis rather than retrospective analysis.\n",
      "\n",
      "Question: How does the guide describe the transformation of data into actionable insights through the creation of data products?\n",
      "Answer: 1. Data Science is described as the art of turning data into actions.\n",
      "    2. This transformation occurs through the creation of data products.\n",
      "    3. Data products provide actionable information without revealing underlying data or analytics.\n",
      "    4. Decision makers benefit from data products without being exposed to raw data.\n",
      "    5. The consolidation of data allows organizations to make informed decisions based on complete information.\n",
      "\n",
      "Question: According to the guide, what role does the Data Lake play in the preparation and analysis of data for Data Science endeavors?\n",
      "Answer: 1. The Data Lake is a tool used by Data Scientists for preparing data for analysis.\n",
      "    2. It consolidates an organization's complete repository of data into a single, large view.\n",
      "    3. Eliminating the need for costly and cumbersome ETL process.\n",
      "    4. All data in the Data Lake is available for every inquiry, reducing the effort required for analysis.\n",
      "    5. By analyzing the data in the Data Lake, Data Scientists can discover new connections and patterns, leading to valuable insights.\n",
      "\n",
      "Question: Can you explain the concept of 'Data Science Maturity' within an organization as presented in the guide, and how does it impact the organization's analytical capabilities?\n",
      "Answer: 1. Data Science Maturity refers to the progression of an organization's Data Science capability from basic data collection to advanced predictive and advisory stages.\n",
      "    2. Each maturity stage requires specific processes, people, culture, and operating models to effectively tackle more complex analytic goals.\n",
      "    3. The maturity model includes stages like Collect, Describe, Discover, Predict, and Advise, with increasing effort and complexity at each stage.\n",
      "    4. Organizations do not need to reach maximum maturity to achieve success; significant gains can be made at every stage.\n",
      "    5. Data Science teams require a broad organizational perspective and a culture that fosters curiosity, transparency, and trust.\n",
      "\n",
      "Question: The guide mentions a 'Data Science Venn Diagram' that includes domain expertise, computer science, and mathematics. How does this diagram illustrate the interdisciplinary nature of Data Science, and why are these areas critical?\n",
      "Answer: 1. The Data Science Venn Diagram represents the interdisciplinary nature of Data Science by highlighting the importance of computer science, mathematics, and domain expertise.\n",
      "    2. Computer science provides the environment for testing data-driven hypotheses, making it essential for Data Science.\n",
      "    3. Mathematics is crucial for understanding patterns and relationships in data, which is a key aspect of Data Science.\n",
      "    4. Domain expertise ensures that Data Science is applied effectively to real-world problems and industries.\n",
      "    5. The combination of these three areas enables Data Scientists to discover new questions, work collaboratively, and focus on future applications rather than just past data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_response = chain_and_QA_process(mistral_llm)\n",
    "\n",
    "for i,j in zip(llm_response[\"Questions\"],llm_response[\"Answers\"]):\n",
    "    print(f\"Question: {i}\\nAnswer: {j}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm-model</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>What are the fundamental differences between d...</td>\n",
       "      <td>1. Deductive reasoning is commonly associated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>How does the guide describe the transformation...</td>\n",
       "      <td>1. Data Science is described as the art of tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>According to the guide, what role does the Dat...</td>\n",
       "      <td>1. The Data Lake is a tool used by Data Scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>Can you explain the concept of 'Data Science M...</td>\n",
       "      <td>1. Data Science Maturity refers to the progres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>The guide mentions a 'Data Science Venn Diagra...</td>\n",
       "      <td>1. The Data Science Venn Diagram represents th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  llm-model  \\\n",
       "0  Mistral-7B-Instruct-v0.2   \n",
       "1  Mistral-7B-Instruct-v0.2   \n",
       "2  Mistral-7B-Instruct-v0.2   \n",
       "3  Mistral-7B-Instruct-v0.2   \n",
       "4  Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                                           Questions  \\\n",
       "0  What are the fundamental differences between d...   \n",
       "1  How does the guide describe the transformation...   \n",
       "2  According to the guide, what role does the Dat...   \n",
       "3  Can you explain the concept of 'Data Science M...   \n",
       "4  The guide mentions a 'Data Science Venn Diagra...   \n",
       "\n",
       "                                             Answers  \n",
       "0  1. Deductive reasoning is commonly associated ...  \n",
       "1  1. Data Science is described as the art of tur...  \n",
       "2  1. The Data Lake is a tool used by Data Scient...  \n",
       "3  1. Data Science Maturity refers to the progres...  \n",
       "4  1. The Data Science Venn Diagram represents th...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(llm_response)\n",
    "\n",
    "df_results = pd.DataFrame(llm_response)\n",
    "df_results[\"llm-model\"] = \"Mistral-7B-Instruct-v0.2\"\n",
    "df_results = df_results[[\"llm-model\",\"Questions\",\"Answers\"]]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model LargeWorldModel-LWM-Text-Chat-256K*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86922fe0cd4941f4b75bd662692b564d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89694252adbe43a58e3d1fb3a409a711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='LargeWorldModel/LWM-Text-Chat-256K'\n",
    "\n",
    "lwm_llm = create_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/PV/envs/llm_work_space/lib/python3.10/site-packages/transformers/generation/utils.py:2677: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /opt/app-root/src/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the fundamental differences between deductive and inductive reasoning in the context of Data Science, as outlined in the guide?\n",
      "Answer: 1. The fundamental difference between deductive and inductive reasoning in the context of Data Science is that deductive reasoning involves reasoning from known premises to a certain conclusion, while inductive reasoning involves drawing uncertain inferences based on probabilistic reasoning.\n",
      "    2. Data Science combines both deductive and inductive reasoning to create a more comprehensive understanding of data and develop better models of reality.\n",
      "    3. The role of deductive reasoning in Data Science is to formulate hypotheses about relationships and underlying models, carry out experiments with the data to test hypotheses and models, and refine existing models based on new insights gained from the data.\n",
      "    4. The role of inductive reasoning in Data Science is to explore the data, discover new relationships and insights, and create new analytic paths from the data.\n",
      "    5. Both types of reasoning play a crucial role in the tradecraft of Data Science, allowing for the discovery of significant insights and the creation of actionable information from data.\n",
      "\n",
      "Question: How does the guide describe the transformation of data into actionable insights through the creation of data products?\n",
      "Answer: 1. The guide describes Data Science as the art of turning data into actions through the creation of data products that provide actionable information without exposing decision makers to the underlying data or analytics. It also explains that performing Data Science requires extracting timely, actionable information from diverse data sources to drive data products.\n",
      "\n",
      "Question: According to the guide, what role does the Data Lake play in the preparation and analysis of data for Data Science endeavors?\n",
      "Answer:  The Data Lake serves as a central repository for an organization's complete repository of data, allowing for easy access and integration of disparate sources. It eliminates the need for costly ETL processes and provides a single view of all data for analysis. The Data Scientist uses analytics to gain insights from the data, which enables real-time understanding and decision-making.\n",
      "\n",
      "Question: Can you explain the concept of 'Data Science Maturity' within an organization as presented in the guide, and how does it impact the organization's analytical capabilities?\n",
      "Answer: 1. The concept of 'Data Science Maturity' refers to an organization's progress in developing and implementing a robust Data Science capability, which includes the correct processes, people, culture, and operating model. It impacts an organization's analytical capabilities by driving them towards the right in the model diagram, where they can focus on advanced Predict and Advise activities. 2. The Data Science Maturity Model provides a common framework for describing the maturity progression and components that make up a Data Science capability. Assessing the maturity of an organization's Data Science capability involves using this framework to determine the analytic goals encompassed and the difficulty and suitability of each goal for the organization.\n",
      "\n",
      "Question: The guide mentions a 'Data Science Venn Diagram' that includes domain expertise, computer science, and mathematics. How does this diagram illustrate the interdisciplinary nature of Data Science, and why are these areas critical?\n",
      "Answer: 1. The Data Science Venn Diagram illustrates the interdisciplinary nature of Data Science by showing how computer science, mathematics, and domain expertise intersect to form a team that can solve complex problems using data. These areas are critical because they provide the foundation for creating effective data products that can improve business outcomes.\n",
      "    2. Building a Data Science capability requires a diverse set of skills, including computer science, mathematics, and domain expertise. This team must work together to build effective data products that can improve business outcomes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_response = chain_and_QA_process(lwm_llm)\n",
    "\n",
    "for i,j in zip(llm_response[\"Questions\"],llm_response[\"Answers\"]):\n",
    "    print(f\"Question: {i}\\nAnswer: {j}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm-model</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LargeWorldModel-LWM-Text-Chat-256K</td>\n",
       "      <td>What are the fundamental differences between d...</td>\n",
       "      <td>1. The fundamental difference between deductiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LargeWorldModel-LWM-Text-Chat-256K</td>\n",
       "      <td>How does the guide describe the transformation...</td>\n",
       "      <td>1. The guide describes Data Science as the art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LargeWorldModel-LWM-Text-Chat-256K</td>\n",
       "      <td>According to the guide, what role does the Dat...</td>\n",
       "      <td>The Data Lake serves as a central repository ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LargeWorldModel-LWM-Text-Chat-256K</td>\n",
       "      <td>Can you explain the concept of 'Data Science M...</td>\n",
       "      <td>1. The concept of 'Data Science Maturity' refe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LargeWorldModel-LWM-Text-Chat-256K</td>\n",
       "      <td>The guide mentions a 'Data Science Venn Diagra...</td>\n",
       "      <td>1. The Data Science Venn Diagram illustrates t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            llm-model  \\\n",
       "0  LargeWorldModel-LWM-Text-Chat-256K   \n",
       "1  LargeWorldModel-LWM-Text-Chat-256K   \n",
       "2  LargeWorldModel-LWM-Text-Chat-256K   \n",
       "3  LargeWorldModel-LWM-Text-Chat-256K   \n",
       "4  LargeWorldModel-LWM-Text-Chat-256K   \n",
       "\n",
       "                                           Questions  \\\n",
       "0  What are the fundamental differences between d...   \n",
       "1  How does the guide describe the transformation...   \n",
       "2  According to the guide, what role does the Dat...   \n",
       "3  Can you explain the concept of 'Data Science M...   \n",
       "4  The guide mentions a 'Data Science Venn Diagra...   \n",
       "\n",
       "                                             Answers  \n",
       "0  1. The fundamental difference between deductiv...  \n",
       "1  1. The guide describes Data Science as the art...  \n",
       "2   The Data Lake serves as a central repository ...  \n",
       "3  1. The concept of 'Data Science Maturity' refe...  \n",
       "4  1. The Data Science Venn Diagram illustrates t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(llm_response)\n",
    "\n",
    "df_results = pd.DataFrame(llm_response)\n",
    "df_results[\"llm-model\"] = \"LargeWorldModel-LWM-Text-Chat-256K\"\n",
    "df_results = df_results[[\"llm-model\",\"Questions\",\"Answers\"]]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Model AzureOpenai-GPT-35-turbo-16k*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/PV/envs/llm_work_space/lib/python3.10/site-packages/langchain_community/chat_models/azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://paycell-arge.openai.azure.com/ to https://paycell-arge.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "/opt/app-root/src/PV/envs/llm_work_space/lib/python3.10/site-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/opt/app-root/src/PV/envs/llm_work_space/lib/python3.10/site-packages/langchain_community/chat_models/azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://paycell-arge.openai.azure.com/ to https://paycell-arge.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'\n",
    "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
    "os.environ['OPENAI_API_VERSION'] = '2023-03-15-preview'\n",
    "os.environ['OPENAI_API_BASE'] = 'OPENAI_API_BASE'\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "      deployment_name=\"deployment_name\",\n",
    "      model_name=\"gpt-35-turbo-16k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the fundamental differences between deductive and inductive reasoning in the context of Data Science, as outlined in the guide?\n",
      "Answer: The fundamental differences between deductive and inductive reasoning in the context of Data Science, as outlined in the guide, are that deductive reasoning involves reasoning from known premises to a certain conclusion, while inductive reasoning involves drawing uncertain inferences based on probabilistic reasoning. Deductive reasoning is commonly associated with \"formal logic\" and produces certain and inevitable conclusions, while inductive reasoning is commonly known as \"informal logic\" and produces probable and reasonable conclusions. Data Science encourages shifting between deductive and inductive reasoning, allowing for the formulation and testing of hypotheses as well as exploratory data analysis to discover new insights and relationships. Data Science also supports the creation of constantly tested, updated, and improved models of reality.\n",
      "\n",
      "Question: How does the guide describe the transformation of data into actionable insights through the creation of data products?\n",
      "Answer: The guide describes the transformation of data into actionable insights through the creation of data products. Data products provide actionable information without exposing decision makers to the underlying data or analytics. Data science tradecraft is the process, tools, and technologies used to transform data into insights. Data science supports shifting between deductive (hypothesis-based) and inductive (pattern-based) reasoning, allowing for the formation or refinement of hypotheses and the discovery of new analytic paths. Models of reality are no longer static and are constantly evolving.\n",
      "\n",
      "Question: According to the guide, what role does the Data Lake play in the preparation and analysis of data for Data Science endeavors?\n",
      "Answer: The Data Lake plays a role in the preparation and analysis of data for Data Science endeavors by providing Data Scientists with access to an organization's complete repository of data. It allows Data Scientists to explore and analyze all the data, leading to new opportunities for analysis and data-driven decision making. The Data Lake eliminates the need for the expensive and cumbersome data-preparation process known as ETL. It enables analytics to find connections and patterns that point to promising opportunities within the data. The Data Lake facilitates high-speed analytic connection within the lake, allowing Data Scientists to bring their analytics to the data.\n",
      "\n",
      "Question: Can you explain the concept of 'Data Science Maturity' within an organization as presented in the guide, and how does it impact the organization's analytical capabilities?\n",
      "Answer: The concept of 'Data Science Maturity' within an organization refers to the progression of the organization's capabilities in the field of data science. It involves moving from basic data collection and description to more advanced stages such as discovery, prediction, and advising. As the organization matures in its data science capabilities, it gains the ability to tackle increasingly complex analytic goals and achieve real insights. The impact of data science maturity on an organization's analytical capabilities is significant, as it allows the organization to make data-informed decisions, gain a competitive advantage, and stay relevant in the data economy. However, it is not necessary for an organization to reach maximum data science maturity to achieve success, as significant gains can be found at every stage.\n",
      "\n",
      "Question: The guide mentions a 'Data Science Venn Diagram' that includes domain expertise, computer science, and mathematics. How does this diagram illustrate the interdisciplinary nature of Data Science, and why are these areas critical?\n",
      "Answer: The Data Science Venn Diagram illustrates the interdisciplinary nature of Data Science by showing the three critical areas that are required for success: domain expertise, computer science, and mathematics. These areas are critical because they provide the foundation for data-driven hypotheses, testing, and analysis. Domain expertise allows for understanding the context and reality of the problem space. Computer science provides the environment for creating data products and testing hypotheses. Mathematics provides the theoretical structure for examining Data Science problems. Together, these areas ensure a well-rounded and comprehensive approach to Data Science.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_response = chain_and_QA_process(llm)\n",
    "\n",
    "for i,j in zip(llm_response[\"Questions\"],llm_response[\"Answers\"]):\n",
    "    print(f\"Question: {i}\\nAnswer: {j}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm-model</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AzureOpenai-GPT-35-turbo-16k</td>\n",
       "      <td>What are the fundamental differences between d...</td>\n",
       "      <td>The fundamental differences between deductive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AzureOpenai-GPT-35-turbo-16k</td>\n",
       "      <td>How does the guide describe the transformation...</td>\n",
       "      <td>The guide describes the transformation of data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AzureOpenai-GPT-35-turbo-16k</td>\n",
       "      <td>According to the guide, what role does the Dat...</td>\n",
       "      <td>The Data Lake plays a role in the preparation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AzureOpenai-GPT-35-turbo-16k</td>\n",
       "      <td>Can you explain the concept of 'Data Science M...</td>\n",
       "      <td>The concept of 'Data Science Maturity' within ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AzureOpenai-GPT-35-turbo-16k</td>\n",
       "      <td>The guide mentions a 'Data Science Venn Diagra...</td>\n",
       "      <td>The Data Science Venn Diagram illustrates the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      llm-model  \\\n",
       "0  AzureOpenai-GPT-35-turbo-16k   \n",
       "1  AzureOpenai-GPT-35-turbo-16k   \n",
       "2  AzureOpenai-GPT-35-turbo-16k   \n",
       "3  AzureOpenai-GPT-35-turbo-16k   \n",
       "4  AzureOpenai-GPT-35-turbo-16k   \n",
       "\n",
       "                                           Questions  \\\n",
       "0  What are the fundamental differences between d...   \n",
       "1  How does the guide describe the transformation...   \n",
       "2  According to the guide, what role does the Dat...   \n",
       "3  Can you explain the concept of 'Data Science M...   \n",
       "4  The guide mentions a 'Data Science Venn Diagra...   \n",
       "\n",
       "                                             Answers  \n",
       "0  The fundamental differences between deductive ...  \n",
       "1  The guide describes the transformation of data...  \n",
       "2  The Data Lake plays a role in the preparation ...  \n",
       "3  The concept of 'Data Science Maturity' within ...  \n",
       "4  The Data Science Venn Diagram illustrates the ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(llm_response)\n",
    "\n",
    "df_results = pd.DataFrame(llm_response)\n",
    "df_results[\"llm-model\"] = \"AzureOpenai-GPT-35-turbo-16k\"\n",
    "df_results = df_results[[\"llm-model\",\"Questions\",\"Answers\"]]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_work_space",
   "language": "python",
   "name": "llm_work_space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
